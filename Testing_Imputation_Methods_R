---
title: "Projekt Symulacje i Imputacje danych"
author: "Jakub Szajner 269383"
date: "`r Sys.Date()`"
output: html_document
---
1. Tematyka projektu
2. Wygenerowanie danych
3. Wygenerowanie braków danych
4. Zbadanie braków danych
5. Imputacja braków danych
6. Symulacja
7. Funkcja
8. Podsumowanie

#1. Opis projektu
Projekt ten ma na celu sprawdzenie i porównanie trzech różnych metod imputacji danych zaimplementowanych w pakietach języka R. Są to kolejno funkcje:
 - *hotdeck()*
 - *kNN()*
 - *matchImpute()*
W ramach praktycznego użycia metod imputacji i symulacji posłużę się dość życiowym przykładem, gdyż będą to wyniki rzeszy studentów z danego egzaminu. 
Zakładamy, że egzamin na wielkiej uczelni pisało *n* studentów. Jako że grupa jest dość równomierna, ich wyniki zostaną wygenerowane z rozkładu równomiernego z odpowiednimi przedziałami. Dalsza część projektu będzie opisywana na bieżąco w podpunktach.

#2. Wgranie niezbędnych pakietów
```{r}
library(VIM)
library(dplyr)
library(mice)
library(nortest)
library(misty)
library(naniar)
library(car)
library(ggplot2)
```

#3. Generowanie danych
Załóżmy, że:
  30% studentów nie zdało egzaminu
  50% studentów uzyskało wyniki od 51 do 80%
  20% studentów uzyskało wyniki od 81 do 100%
Wygenerujemy te dane z rozkładu równomiernego (zakładamy, że studenci są bardzo równi w swoich 'przedziałach':
```{r}
liczba_obserwacji = 500
grupa1 = floor(runif(0.3*liczba_obserwacji,0,50))
grupa2 = floor(runif(0.5*liczba_obserwacji,51,80))
grupa3 = floor(runif(0.2*liczba_obserwacji,81,101))
punkty = matrix(c(grupa1, grupa2, grupa3),nrow = liczba_obserwacji, ncol = 1)
hist(punkty)
punkty1 = punkty
ocena <- recode(punkty1, "0:50 = '2'; 51:60 = '3'; 61:70 = '3+';71:80 = '4'; 81:90 = '4+'; else = 5")
barplot(table(ocena))
```
Na powyższym histogramie i wykresie słupkowym został przedstawiony rozkład wyników z egzaminu oraz rozłożenie ocen. Widać, iż spora grupa studentów egzaminu nie zdała, aczkolwiek stanowią oni tylko 30% całkowitej populacji. Reszta ocen układa się w sposób w miarę równomierny, z delikatną przewagą ocen niższych - jak to w prawdziwym życiu.

Łączymy wygenerowane dane w jeden zbiór danych, na podstawie którego odbywać będą się dalsze działania. Statystyki opisowe wygenerowane tutaj wykorzystane zostaną także pod koniec, w celu sprawdzenia skuteczności metod imputacji.
```{r}
wynik = cbind(punkty, ocena)
wynik = data.frame(wynik)
colnames(wynik) = c('Punkty', 'Ocena')
wynik$Punkty = as.numeric(wynik$Punkty)
wynik$Ocena = as.factor(wynik$Ocena)
summary(wynik)
```
Zbiór danych wygląda następująco:
```{r}
head(wynik)
```

#4. Generowanie braków danych
Załóżmy że:
  studenci z 2 beda odpowiadac za 80% brakow danych,
  studenci z lepszymi ocenami: za 20%.
Możemy uznać, że nasze dane są danymi uzyskanymi z kwestionariusza ankiety przeprowadzonego wśród studentów. Znaliśmy liczbę poszczególnych ocen od prowadzącego przedmiot aczkolwiek nie poznaliśmy dokładnych wyników. Niechęć do dzielenia się niższymi ocenami jest czymś naturalnym, więc dlatego ten sposób generowania braków został wybrany.
```{r}
wynik1 = wynik
braki = 50
braki_low = 0.8 * braki
while (sum(is.na(wynik1[,1])) < braki_low) {
  los = sample(1:liczba_obserwacji,1)
  if (wynik[los,1] <= 50) {
    wynik1[los,1] = NA
  }
}
while (sum(is.na(wynik1[,1]))<braki) {
  los = sample(1:liczba_obserwacji,1)
  if (wynik[los,1] > 50) {
    wynik1[los,1] = NA
  }
}
```

Wygenerowano zaznaczoną wyżej liczbę braków. Pora sprawdzić statystyki zbioru.
```{r}
sum(is.na(wynik1))
summary(wynik1)
summary(wynik)
```

Pierwszą, najbardziej rzucającą się w oczy obserwacją jest znaczne podwyższenie wartości pierwszego kwartyla oraz średniej. Jest to dość oczywiste, bo 40 braków zauważono właśnie wśród tych najgorszych ocen, dlatego też średnia całego zbioru wzrosła. 25% najmniejszych obserwacji również jest 'stosunkowo' większe niż wcześniej.

Braki danych wygenerowane w ten sposób są brakami MAR (Missing at Random), ponieważ zależą one od innej zmiennej w zbiorze lub czynnika spoza zbioru. Tutaj oczywiście jest to skłonność do powstawania braku danych przy niskiej ocenie. 

Można sprawdzić, czy faktycznie nasze braki są to braki MAR.

#5. Testowanie braków danych 
Wykorzystamy podejście alternatywne:
 -utworzymy nową zmienną która przybierze wartość 1 jeżeli występuje brak danych oraz 0 gdy nie występuje
 -stworzymy model regresji logistycznej i sprawdzimy pvalue przy zmiennej określającej wpływ tej powyższej

```{r}
brakwyniku = ifelse(is.na(wynik1$Punkty),1,0)
zdalczynie = ifelse(wynik1$Ocena == "2","nie","tak")
s <- summary(glm(brakwyniku ~ zdalczynie),family=binomial)
s$coefficients[2,4]
```

Wartość pvalue była bliska zeru - oznacza to, że odrzucamy hipotezę zerową w teście indywidualnej istotności parametru strukturalnego. Oznacza to, że w tym przypadku zdecydowanie można stwierdzić, że braki danych w zbiorze są MAR - Missing at Random - czyli zależne od innej zmiennej w zbiorze bądź też poza nim. Możemy przejsć do imputacji tych braków.

#6. Imputacja braków danych
Zaimputujemy braki danych trzema wspomnianymi wcześniej funkcjami.
```{r}
hd_impute = hotdeck(data = wynik1, variable = "Punkty")
knn_impute = kNN(data = wynik1, variable = "Punkty")
match_impute = matchImpute(data = wynik1, variable = "Punkty", match_var = "Ocena")
```

Następnie w celu sprawdzenia statystyk opisowych zbioru po przeprowadzniu imputacji wykonamy następujące działania:
```{r}
hd_impute$Ocena = hd_impute$Punkty
hd_impute$Ocena <- recode(hd_impute$Ocena, "0:50 = '2'; 51:60 = '3'; 61:70 = '3+';71:80 = '4'; 81:90 = '4+'; else = 5")
hd_impute$Ocena = as.factor(hd_impute$Ocena)
hdOceny = table(hd_impute$Ocena)
hdSrednia = mean(hd_impute$Punkty)
hdMediana = median(hd_impute$Punkty)
hd1kw = quantile(hd_impute$Punkty)[2]
hd3kw = quantile(hd_impute$Punkty)[4]
hdstatPunkty = rbind(hdSrednia,hdMediana,hd1kw,hd3kw)
```
To samo dla drugiej metody:
```{r}
knn_impute$Ocena = knn_impute$Punkty
knn_impute$Ocena <- recode(knn_impute$Ocena, "0:50 = '2'; 51:60 = '3'; 61:70 = '3+';71:80 = '4'; 81:90 = '4+'; else = 5")
knn_impute$Ocena = as.factor(knn_impute$Ocena)
knnOceny = table(knn_impute$Ocena)
knnSrednia = mean(knn_impute$Punkty)
knnMediana = median(knn_impute$Punkty)
knn1kw = quantile(knn_impute$Punkty)[2]
knn3kw = quantile(knn_impute$Punkty)[4]
knnstatPunkty = rbind(knnSrednia,knnMediana,knn1kw,knn3kw)
```


I dla trzeciej:
```{r}
match_impute$Ocena = match_impute$Punkty
match_impute$Ocena <- recode(match_impute$Ocena, "0:50 = '2'; 51:60 = '3'; 61:70 = '3+';71:80 = '4'; 81:90 = '4+'; else = 5")
match_impute$Ocena = as.factor(match_impute$Ocena)
matchOceny = table(match_impute$Ocena)
matchSrednia = mean(match_impute$Punkty)
matchMediana = median(match_impute$Punkty)
match1kw = quantile(match_impute$Punkty)[2]
match3kw = quantile(match_impute$Punkty)[4]
matchstatPunkty = rbind(matchSrednia,matchMediana,match1kw,match3kw)
```
Ostatnim krokiem jest zestawienie wszystkich statystyk opisowych z różnych metod. Uzyskujemy w ten sposób dwie tabele - jedna z punktami i statystykami opisowymi dla nich, druga dla ocen i ich liczebności. Widać, że metoda hotdeck najgorzej poradziła sobie z imputacją wygenerowanych danych. Wyniki znacznie różnią się od wyników bazowych - jest to jedyna metoda, przy której występują różnice w liczebności ocen. Metoda match za to jest najbliżej wartości prawdziwych. Zapewne jest to związane z tym, że korzysta ona do imputacji z wartości drugiej zmiennej (w tym wypadku oceny).

```{r}
Oceny = table(wynik1$Ocena)
Srednia = mean(wynik$Punkty)
Mediana = median(wynik$Punkty)
n1kw = quantile(wynik$Punkty)[2]
n3kw = quantile(wynik$Punkty)[4]
statPunkty = rbind(Srednia,Mediana,n1kw,n3kw)
zestawienieOcen = rbind(Oceny,hdOceny,knnOceny,matchOceny)
zestawienieStat = rbind(statPunkty, hdstatPunkty,knnstatPunkty,matchstatPunkty)
zestawienieOcen = data.frame(zestawienieOcen)
rownames(zestawienieOcen) = c("Wyniki bazowe", "Imputacja Hot Deck", "Imputacja kNN", "Imputacja Match")
colnames(zestawienieOcen) = c("2","3","3+","4","4+","5")
zestawienieStat = matrix(zestawienieStat,nrow = 4, ncol = 4, byrow = TRUE)
zestawienieStat = data.frame(zestawienieStat)
rownames(zestawienieStat) = c("Wyniki bazowe", "Imputacja Hot Deck", "Imputacja kNN", "Imputacja Match")
colnames(zestawienieStat) = c("Średnia","Mediana","Pierwszy kwartyl", "Trzeci kwartyl")
zestawienieStat
zestawienieOcen
```

#7. Funkcja
W celu skrócenia kodu oraz otworzenia nowych możliwości analizy, wszystkie obliczenia zostały zebrane w jedną krótką funkcję.
```{r}
porownanieImputacji = function(liczba_obserwacji = 500, braki = 50){
  grupa1 = floor(runif(0.3*liczba_obserwacji,0,50))
  grupa2 = floor(runif(0.5*liczba_obserwacji,51,80))
  grupa3 = floor(runif(0.2*liczba_obserwacji,81,101))
  punkty = matrix(c(grupa1, grupa2, grupa3),nrow = liczba_obserwacji, ncol = 1)
  punkty1 = punkty
  ocena <- recode(punkty1, "0:50 = '2'; 51:60 = '3'; 61:70 = '3+';71:80 = '4'; 81:90 = '4+'; else = 5")
  wynik = cbind(punkty, ocena)
  wynik = data.frame(wynik)
  colnames(wynik) = c('Punkty', 'Ocena')
  wynik$Punkty = as.numeric(wynik$Punkty)
  wynik$Ocena = as.factor(wynik$Ocena)
  wynik1 = wynik
  braki_low = 0.8 * braki
  while (sum(is.na(wynik1[,1])) < braki_low) {
    los = sample(1:liczba_obserwacji,1)
    if (wynik[los,1] <= 50) {
      wynik1[los,1] = NA
    }
  }
  while (sum(is.na(wynik1[,1]))<braki) {
    los = sample(1:liczba_obserwacji,1)
    if (wynik[los,1] > 50) {
      wynik1[los,1] = NA
    }
  }
  hd_impute = hotdeck(data = wynik1, variable = "Punkty")
  knn_impute = kNN(data = wynik1, variable = "Punkty")
  match_impute = matchImpute(data = wynik1, variable = "Punkty", match_var = "Ocena")
  hd_impute$Ocena = hd_impute$Punkty
  hd_impute$Ocena <- recode(hd_impute$Ocena, "0:50 = '2'; 51:60 = '3'; 61:70 = '3+';71:80 = '4'; 81:90 = '4+'; else = 5")
  hd_impute$Ocena = as.factor(hd_impute$Ocena)
  hdOceny = table(hd_impute$Ocena)
  hdSrednia = mean(hd_impute$Punkty)
  hdMediana = median(hd_impute$Punkty)
  hd1kw = quantile(hd_impute$Punkty)[2]
  hd3kw = quantile(hd_impute$Punkty)[4]
  hdstatPunkty = rbind(hdSrednia,hdMediana,hd1kw,hd3kw)
  knn_impute$Ocena = knn_impute$Punkty
  knn_impute$Ocena <- recode(knn_impute$Ocena, "0:50 = '2'; 51:60 = '3'; 61:70 = '3+';71:80 = '4'; 81:90 = '4+'; else = 5")
  knn_impute$Ocena = as.factor(knn_impute$Ocena)
  knnOceny = table(knn_impute$Ocena)
  knnSrednia = mean(knn_impute$Punkty)
  knnMediana = median(knn_impute$Punkty)
  knn1kw = quantile(knn_impute$Punkty)[2]
  knn3kw = quantile(knn_impute$Punkty)[4]
  knnstatPunkty = rbind(knnSrednia,knnMediana,knn1kw,knn3kw)
  match_impute$Ocena = match_impute$Punkty
  match_impute$Ocena <- recode(match_impute$Ocena, "0:50 = '2'; 51:60 = '3'; 61:70 = '3+';71:80 = '4'; 81:90 = '4+'; else = 5")
  match_impute$Ocena = as.factor(match_impute$Ocena)
  matchOceny = table(match_impute$Ocena)
  matchSrednia = mean(match_impute$Punkty)
  matchMediana = median(match_impute$Punkty)
  match1kw = quantile(match_impute$Punkty)[2]
  match3kw = quantile(match_impute$Punkty)[4]
  matchstatPunkty = rbind(matchSrednia,matchMediana,match1kw,match3kw)
  Oceny = table(wynik1$Ocena)
  Srednia = mean(wynik$Punkty)
  Mediana = median(wynik$Punkty)
  n1kw = quantile(wynik$Punkty)[2]
  n3kw = quantile(wynik$Punkty)[4]
  statPunkty = rbind(Srednia,Mediana,n1kw,n3kw)
  zestawienieOcen = rbind(Oceny,hdOceny,knnOceny,matchOceny)
  zestawienieStat = rbind(statPunkty, hdstatPunkty,knnstatPunkty,matchstatPunkty)
  zestawienieOcen = data.frame(zestawienieOcen)
  rownames(zestawienieOcen) = c("Wyniki bazowe", "Imputacja Hot Deck", "Imputacja kNN", "Imputacja Match")
  colnames(zestawienieOcen) = c("2","3","3+","4","4+","5")
  zestawienieStat = matrix(zestawienieStat,nrow = 4, ncol = 4, byrow = TRUE)
  zestawienieStat = data.frame(zestawienieStat)
  rownames(zestawienieStat) = c("Wyniki bazowe", "Imputacja Hot Deck", "Imputacja kNN", "Imputacja Match")
  colnames(zestawienieStat) = c("Średnia","Mediana","Pierwszy kwartyl", "Trzeci kwartyl")
  itylexd = list(zestawienieOcen,zestawienieStat)
  return(itylexd)
}
```

Postać funkcji to: *porownanieImputacji(liczbaobserwacji, braki)*. Wynikiem tej funkcji jest lista z dwoma tabelami przedstawiona i opisana wcześniej. Dzięki tej funkcji, możemy szybko sprawdzić jak kształtują się statystyki opisowe dla różnej liczności obserwacji oraz braków. Ze względów bezpieczeństwa nie zaleca się, aby braki stanowiły ponad 35% zbioru.
```{r}
porownanieImputacji(10000,1000)
```

#8. Podsumowanie
Projekt wykorzystał elementy symulacji komputerowych i imputacji danych, aby zobrazować jak braki danych wpływają na ostateczny kształt zbioru. Uzyskane wyniki mogą posłuzyć do dalszej analizy, także graficznej, by jeszcze dokładniej sprawdzić różnice między funkcjami.
